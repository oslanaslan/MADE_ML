{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Poetry generation\n",
    "\n",
    "Let's try to generate some poetry using RNNs. \n",
    "\n",
    "You have several choices here: \n",
    "\n",
    "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
    "\n",
    "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
    "\n",
    "* Some other text source, if it will be approved by the course staff.\n",
    "\n",
    "Text generation can be designed in several steps:\n",
    "    \n",
    "1. Data loading.\n",
    "2. Dictionary generation.\n",
    "3. Data preprocessing.\n",
    "4. Model (neural network) training.\n",
    "5. Text generation (model evaluation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchsummary\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from random import sample\n",
    "\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading: Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('sonnets.txt'):\n",
    "    !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/21f_basic/homeworks_basic/lab02_deep_learning/sonnets.txt\n",
    "\n",
    "with open('sonnets.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "TEXT_START = 45\n",
    "TEXT_END = -368\n",
    "text = text[TEXT_START : TEXT_END]\n",
    "assert len(text) == 2616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
    "\n",
    "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Join all the strings into one and lowercase it\n",
    "# Put result into variable text.\n",
    "\n",
    "text = ''.join(text).lower()\n",
    "\n",
    "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
    "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading: \"Евгений Онегин\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-20 02:28:30--  https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 262521 (256K) [text/plain]\n",
      "Saving to: ‘onegin.txt.2’\n",
      "\n",
      "onegin.txt.2        100%[===================>] 256,37K  --.-KB/s    in 0,1s    \n",
      "\n",
      "2021-12-20 02:28:30 (1,78 MB/s) - ‘onegin.txt.2’ saved [262521/262521]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
    "    \n",
    "with open('onegin.txt', 'r') as iofile:\n",
    "    russian_text = iofile.readlines()\n",
    "    \n",
    "russian_text = [x.replace('\\t\\t', '') for x in russian_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
    "\n",
    "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the strings into one and lowercase it\n",
    "# Put result into variable text.\n",
    "\n",
    "russian_text = ''.join(russian_text).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all the characters, that you've seen in the text, into variable `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sorted(set(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert not '|' in tokens, (\n",
    "    'special token must not be in tokens'\n",
    ")\n",
    "pad = '|'\n",
    "tokens += [pad]\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dict <index>:<char>\n",
    "# dict <char>:<index>\n",
    "\n",
    "token_to_idx = {char: idx for idx, char in enumerate(tokens)}\n",
    "idx_to_token = {idx: char for idx, char in enumerate(tokens)}\n",
    "\n",
    "sequences = text.split('\\n')\n",
    "sequences = [seq.strip(' ') + '\\n' for seq in sequences]\n",
    "MAX_LENGTH = max(map(len, sequences))\n",
    "sequences = [seq + pad * (MAX_LENGTH - len(seq)) for seq in sequences]\n",
    "\n",
    "assert len(set(map(len, sequences))) == 1, (\n",
    "    \"All sequences must be same length\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_LENGTH: 61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['from fairest creatures we desire increase,\\n||||||||||||||||||',\n",
       " \"that thereby beauty's rose might never die,\\n|||||||||||||||||\",\n",
       " 'but as the riper should by time decease,\\n||||||||||||||||||||',\n",
       " 'his tender heir might bear his memory:\\n||||||||||||||||||||||',\n",
       " 'but thou, contracted to thine own bright eyes,\\n||||||||||||||',\n",
       " \"feed'st thy light's flame with self-substantial fuel,\\n|||||||\",\n",
       " 'making a famine where abundance lies,\\n|||||||||||||||||||||||',\n",
       " 'thy self thy foe, to thy sweet self too cruel:\\n||||||||||||||',\n",
       " \"thou that art now the world's fresh ornament,\\n|||||||||||||||\",\n",
       " 'and only herald to the gaudy spring,\\n||||||||||||||||||||||||']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"MAX_LENGTH: {MAX_LENGTH}\")\n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(sequences, max_len=None, pad=token_to_idx['|'], dtype='int32', batch_first = True):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, sequences))\n",
    "    seq_ix = np.zeros([len(sequences), max_len], dtype) + pad\n",
    "\n",
    "    for i, seq in enumerate(sequences):\n",
    "        line_ix = [token_to_idx[c] for c in seq]\n",
    "        seq_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first:\n",
    "        names_ix = np.transpose(seq_ix)\n",
    "\n",
    "    return seq_ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
    "\n",
    "Let's use vanilla RNN, similar to the one created during the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanilaRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=64, rnn_num_units=512):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
    "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "        x_emb = self.embedding(x).to(device)\n",
    "        h_prev = torch.tensor(h_prev).to(device)\n",
    "        x_and_h = torch.cat([x_emb, h_prev], dim=-1)\n",
    "        h_next = self.rnn_update(x_and_h)\n",
    "        h_next = torch.tanh(h_next)\n",
    "        \n",
    "        assert h_next.size() == h_prev.size()\n",
    "        \n",
    "        logits = self.rnn_to_logits(h_next)\n",
    "        \n",
    "        return h_next, nn.functional.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
    "        return torch.zeros(batch_size, self.num_units, requires_grad=True)\n",
    "    \n",
    "def rnn_loop(model, batch_ix):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in names_ix\n",
    "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
    "    \"\"\"\n",
    "    batch_size, max_length = batch_ix.size()\n",
    "    hid_state = model.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    for x_t in batch_ix.transpose(0,1):\n",
    "        hid_state, logp_next = model(x_t, hid_state)  # <-- here we call your one-step code\n",
    "        logprobs.append(logp_next)\n",
    "        \n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_size = len(token_to_idx)\n",
    "hidden_dim = 512\n",
    "n_layers = 7\n",
    "\n",
    "model = VanilaRNN()\n",
    "model = model.to(device)\n",
    "\n",
    "n_epochs = 50000\n",
    "lr=0.01\n",
    "\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [22:33<00:00, 36.95it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loss_lst = []\n",
    "plot_tick = 100\n",
    "\n",
    "for i in tqdm(range(n_epochs)):\n",
    "    batch_ix = to_matrix(sample(sequences, 32))\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64).to(device)\n",
    "    \n",
    "    logp_seq = rnn_loop(model, batch_ix)\n",
    "    predictions_logp = logp_seq[:, :-1]\n",
    "    actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "    loss = loss_func(predictions_logp.reshape(-1, dict_size), actual_next_tokens.reshape(-1))\n",
    "    \n",
    "    # train with backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss_lst.append(loss.data.to('cpu').numpy())\n",
    "\n",
    "    if (i + 1) % plot_tick == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(train_loss_lst, label='Loss')\n",
    "        plt.grid()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title(f\"Current loss: {np.mean(train_loss_lst[:-100])}\")\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(train_loss_lst[:10]) > np.mean(train_loss_lst[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of generated text.\n",
    "# print(generate_text(length=500, temperature=0.2))\n",
    "\n",
    "def generate_text(model, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64).to(device)\n",
    "    hid_state = model.initial_state(batch_size=1)\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        hid_state, _ = model(x_sequence[:, i], hid_state)\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        hid_state, logp_next = model(x_sequence[:, -1], hid_state)\n",
    "        p_next = nn.functional.softmax(logp_next.detach() / temperature, dim=-1).data.detach().to('cpu').numpy()[0]\n",
    "        \n",
    "        # sample next token and push it back into x_sequence\n",
    "        next_ix = np.random.choice(dict_size, p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64).to(device)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.to('cpu').numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real text:\n",
      "\n",
      "from fairest creatures we desire increase,\n",
      "that thereby beauty's rose might never die,\n",
      "but as the riper should by time decease,\n",
      "his tender heir might bear his memory:\n",
      "but thou, contracted to thine own bright eyes,\n",
      "\n",
      "text seed: from fairest\n"
     ]
    }
   ],
   "source": [
    "seed_text = sequences[0].split(' ')[:2]\n",
    "print('Real text:\\n')\n",
    "print(''.join([sequences[i].strip('|') for i in range(5)]))\n",
    "seed_text = ' '.join(seed_text)\n",
    "print(f'text seed: {seed_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aslan/anaconda3/envs/dl_env/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'from fairest the with the with the sure and the love the seeds of the sure the prown the sure my love the so me the with the see the so the worth the sweet i self the see the worth the seem the stare the sing the see thou art thou art the see the see the deart the stall the wair the wert the with the sone and the see the see a see the worth the seep the see the self the so beauty the see the stare the strease the with the self the the with the with the seeds of the seem the sure the sone of the '"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 500\n",
    "temperature = 0.2\n",
    "generate_text(model, seed_text, length, temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More poetic model\n",
    "\n",
    "Let's use LSTM instead of vanilla RNN and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function of the number of epochs. Does the final loss become better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your beautiful code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
    "\n",
    "Evaluate the results visually, try to interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Text generation with different temperature values here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving and loading code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
    "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
    "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
    "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
